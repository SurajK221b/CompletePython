{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet Lemmatizer\n",
    "Lemmatization technique is like stemming. The output we will get after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
    "\n",
    "NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma. Let us understand it with an example −\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization is the process of reducing a word to its base or dictionary form (called a lemma) by considering the context such as part of speech (POS) and morphological analysis.\n",
    "\n",
    "\"running\" → \"run\"\n",
    "\n",
    "\"better\" → \"good\"\n",
    "\n",
    "\"mice\" → \"mouse\"\n",
    "\n",
    "Lemmatization requires linguistic knowledge, unlike stemming which blindly strips suffixes.\n",
    "\n",
    "### Why is Lemmatization Important?\n",
    "\n",
    "| Benefit                           | Explanation                                                        |\n",
    "| --------------------------------- | ------------------------------------------------------------------ |\n",
    "| ✅ Accurate root words             | Ensures valid dictionary forms (e.g., “was” → “be”)                |\n",
    "| ✅ Context-aware normalization     | Considers word meaning and part of speech                          |\n",
    "| ✅ Useful for downstream NLP tasks | Improves accuracy in parsing, tagging, NER, and sentiment analysis |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Suraj\n",
      "[nltk_data]     Khodade\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Q&A,chatbots,text summarization\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "POS- Noun-n\n",
    "verb-v\n",
    "adjective-a\n",
    "adverb-r\n",
    "'''\n",
    "lemmatizer.lemmatize(\"going\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"historical\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eat\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "historical---->historical\n",
      "finally---->finally\n",
      "finalized---->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"goes\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairly', 'sportingly')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"fairly\",pos='v'),lemmatizer.lemmatize(\"sportingly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview Questions – Lemmatization\n",
    "\n",
    "### Q1. What is lemmatization and how does it differ from stemming?\n",
    "#### Lemmatization maps words to their canonical dictionary form using linguistic analysis, while stemming strips affixes without understanding context.\n",
    "\n",
    "### Q2. Why is POS tagging important for lemmatization?\n",
    "#### Many words have different lemmas based on their part of speech. For instance:\n",
    "\n",
    "\"better\" as adjective → \"good\"  \n",
    "\"better\" as verb → \"better\"\n",
    "\n",
    "Providing correct POS improves lemmatization accuracy.\n",
    "\n",
    "### Q3. Can you explain how WordNetLemmatizer works?\n",
    "#### It uses the WordNet lexical database to look up lemmas based on word and optional POS tag. It’s slower but more accurate than stemming.\n",
    "\n",
    "### Q4. In which NLP scenarios would you prefer lemmatization over stemming?\n",
    "#### In tasks like named entity recognition (NER), POS tagging, machine translation, and text classification where linguistic correctness matters.\n",
    "\n",
    "### Q5. What are the limitations of lemmatization?\n",
    "#### Requires language-specific corpora (e.g., WordNet)  \n",
    "Slower compared to stemming  \n",
    "May not capture domain-specific root forms unless customized\n",
    "\n",
    "### ✅ Summary\n",
    "| When to Use           | Recommendation                                 |\n",
    "|-----------------------|------------------------------------------------|\n",
    "| Search Engines        | Stemming (performance > precision)             |\n",
    "| Language Understanding| Lemmatization (accuracy > speed)               |\n",
    "| Domain-specific tasks | Use lemmatizer + custom dictionaries           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization vs. Stemming\n",
    "\n",
    "| Feature           | **Lemmatization**                      | **Stemming**                        |\n",
    "| ----------------- | -------------------------------------- | ----------------------------------- |\n",
    "| Output            | Valid dictionary words                 | May produce non-words               |\n",
    "| Context-sensitive | Yes (POS-aware)                        | No                                  |\n",
    "| Accuracy          | High                                   | Low to moderate                     |\n",
    "| Speed             | Slower (due to linguistic analysis)    | Faster (rule-based)                 |\n",
    "| Library           | `WordNetLemmatizer`                    | `PorterStemmer`, `Lancaster`, etc.  |\n",
    "| Example           | `\"running\"` → `\"run\"`                  | `\"running\"` → `\"run\"` or `\"runn\"`   |\n",
    "| Use case          | NLP tasks needing grammatical accuracy | IR, search indexing, high-speed NLP |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
